{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from Score.helpers import *\n",
    "from Score.algorithms import trustworthiness\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Specify evaluation scenario & limited\n",
    "scenario = \"creditrisk\" # diabetes or creditrisk\n",
    "limited = False # if True, computes metrics that do not depend on DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# ********** Load respective model and dataset ************\n",
    "if scenario == \"diabetes\":\n",
    "        solution = \"Solutions/S1DiabetesPredictionRF/TrueScore\"\n",
    "        model = pickle.load(open(f\"{solution}/model.pkl\", \"rb\")) # RF\n",
    "        target_column = \"diabetes\"\n",
    "elif scenario == \"creditrisk\":\n",
    "        solution = \"Solutions/S2HomeCreditDefaultRiskDNN/TrueScore\"\n",
    "        model = keras.models.load_model(f\"{solution}/model.keras\") # DNN\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "        target_column = \"TARGET\"\n",
    "else:\n",
    "        raise AssertionError(\"Check specifications: Evaluation scenario does not exist\")\n",
    "if limited:\n",
    "        train = None\n",
    "        test = None\n",
    "        solution = f\"{'/'.join(solution.split('/')[:-1])}/LimitedScore\"\n",
    "else:\n",
    "        train = pd.read_csv(f\"{solution}/train.csv\")\n",
    "        test = pd.read_csv(f\"{solution}/test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********** Compute TRUE Score ************\n",
    "factsheet = json.load(open(f\"{solution}/factsheet.json\"))\n",
    "config_fairness = json.load(open(f\"Score/configs/mappings/fairness/default.json\"))\n",
    "config_exp = json.load(open(f\"Score/configs/mappings/explainability/default.json\"))\n",
    "config_rob = json.load(open(f\"Score/configs/mappings/robustness/default.json\"))\n",
    "config_met = json.load(open(f\"Score/configs/mappings/methodology/default.json\"))\n",
    "config_weights = json.load(open(f\"Score/configs/weights/default.json\"))\n",
    "solution_set_path = f\"{solution}/\"\n",
    "mappings_config = {}\n",
    "mappings_config[\"fairness\"] = config_fairness\n",
    "mappings_config[\"explainability\"] = config_exp\n",
    "mappings_config[\"robustness\"] = config_rob\n",
    "mappings_config[\"methodology\"] = config_met\n",
    "result = trustworthiness.get_final_score(model, train, test, config_weights, mappings_config, factsheet, solution_set_path, recalc=False)\n",
    "true_final_scores, true_results, true_properties = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ********** Plotting for Report ************\n",
    "from Score.plot import *\n",
    "\n",
    "trust_score = trustworthiness.get_trust_score(true_final_scores, config_weights[\"pillars\"])\n",
    "data = {\"final_score\":true_final_scores,\n",
    "        \"results\":true_results,\n",
    "        \"trust_score\":trust_score,\n",
    "        \"properties\" : true_properties}\n",
    "\n",
    "final_score = data[\"final_score\"]\n",
    "pillars = list(final_score.keys())\n",
    "values = list(final_score.values())\n",
    "pillar_colors = ['#06d6a0', '#ffd166', '#ef476f', '#118ab2']\n",
    "title = \"Overall Trust Score {}/5\".format(trust_score)\n",
    "figname = \"overall.png\"\n",
    "\n",
    "draw_bar_plot(pillars, values, pillar_colors, title, figname, solution)\n",
    "draw_pillar_scores(data['results'], final_score, pillar_colors, solution)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
