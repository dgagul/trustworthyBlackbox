{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import keras\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ********** Load and clean dataset ************\n",
    "# Download the dateset here: https://www.kaggle.com/competitions/home-credit-default-risk/data?select=application_train.csv\n",
    "data = pd.read_csv(\"application_train.csv\")\n",
    "print(data.shape)\n",
    "\n",
    "reduced_data = data[[\"TARGET\",\"CODE_GENDER\",\"FLAG_OWN_CAR\",\"FLAG_OWN_REALTY\",\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"NAME_EDUCATION_TYPE\",\"REGION_RATING_CLIENT\",\"CNT_FAM_MEMBERS\"]]\n",
    "data = reduced_data[~reduced_data[\"CNT_FAM_MEMBERS\"].isna()]\n",
    "data.dropna()\n",
    "print(data.shape)\n",
    "data.to_csv(\"credit_risk.csv\", index=False)\n",
    "\n",
    "for cat in [\"CODE_GENDER\",\"FLAG_OWN_CAR\",\"FLAG_OWN_REALTY\",\"NAME_EDUCATION_TYPE\"]:\n",
    "    # Encode the categorical data using sequential numbers\n",
    "    feature = list(data[cat].unique())\n",
    "    print(feature)\n",
    "    data[cat].replace(feature, [i for i, _ in enumerate(feature)], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ********** Split dataset and prepare for training ************\n",
    "y = data[['TARGET']]\n",
    "X = data.drop('TARGET', axis = 1)\n",
    "\n",
    "# convert pandas DataFrame (X) and numpy array (y) into PyTorch tensors\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "# n_classes = y.shape[1]\n",
    "n_classes = torch.unique(y).shape[0]\n",
    "print(n_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ********** Define and instantiate Sequential model ************\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# compute weights to account for unbalanced labels\n",
    "tot_y = data[data[\"TARGET\"] == 1].shape[0]\n",
    "tot_n = data[data[\"TARGET\"] == 0].shape[0]\n",
    "w_y = tot_y / data.shape[0]\n",
    "w_n = tot_n / data.shape[0]\n",
    "\n",
    "# loss metric and optimizer\n",
    "input_size, hidden_size, output_size = (n_features, 10, n_classes)\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([w_n,w_y]))\n",
    "loss_fn.requires_grad = True\n",
    "params = list(model.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ********** Actual Training ************\n",
    "n_epochs = 4\n",
    "batch_size = 100\n",
    "batches_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "best_acc = - np.inf   # init to negative infinity\n",
    "best_weights = None\n",
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "test_loss_hist = []\n",
    "test_acc_hist = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    # set model in training mode and run through each batch\n",
    "    model.train()\n",
    "    with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for i in bar:\n",
    "            # take a batch\n",
    "            start = i * batch_size\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch.flatten())\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # compute and store metrics\n",
    "            acc = (torch.argmax(y_pred, 1) == y_batch.flatten()).float().mean()\n",
    "            epoch_loss.append(float(loss))\n",
    "            epoch_acc.append(float(acc))\n",
    "            bar.set_postfix(\n",
    "                loss=float(loss),\n",
    "                acc=float(acc)\n",
    "            )\n",
    "    # set model in evaluation mode and run through the test set\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    ce = loss_fn(y_pred, y_test.flatten())\n",
    "    acc = (torch.argmax(y_pred, 1) == y_test.flatten()).float().mean()\n",
    "    ce = float(ce)\n",
    "    acc = float(acc)\n",
    "    train_loss_hist.append(np.mean(epoch_loss))\n",
    "    train_acc_hist.append(np.mean(epoch_acc))\n",
    "    test_loss_hist.append(ce)\n",
    "    test_acc_hist.append(acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "    print(f\"Epoch {epoch} validation: Cross-entropy={ce:.2f}, Accuracy={acc*100:.1f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Restore best model and save it\n",
    "model.load_state_dict(best_weights)\n",
    "torch.save(model.state_dict(), \"pytorch_weights.pth\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert Torch Model to Keras\n",
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(8,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "# Load the PyTorch model weights\n",
    "pytorch_weights = torch.load('pytorch_weights.pth')\n",
    "\n",
    "weights = []\n",
    "layer_weights = []\n",
    "for el in pytorch_weights.values():\n",
    "    if len(el.shape) > 1:\n",
    "        layer_weights.append(torch.transpose(el, 0, 1).numpy())\n",
    "    else:\n",
    "        layer_weights.append(el.numpy())\n",
    "weights.append(list(layer_weights[0:2]))\n",
    "weights.append(list(layer_weights[2:]))\n",
    "\n",
    "# Iterate over the layers in the Keras model and the weights in the PyTorch model\n",
    "for keras_layer, layer_weights in zip(keras_model.layers, weights):\n",
    "    # Set the weights of the corresponding layers in the Keras model\n",
    "    keras_layer.set_weights(layer_weights)\n",
    "\n",
    "keras_model.compile(\n",
    "    # optimizer=optimizer, loss=\"binary_crossentropy\"\n",
    "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Show models are the same\n",
    "t_model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "pytorch_weights = torch.load('pytorch_weights.pth')\n",
    "t_model.load_state_dict(pytorch_weights)\n",
    "\n",
    "randomData = data.sample(100)\n",
    "y = randomData[['TARGET']]\n",
    "X = randomData.drop('TARGET', axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "\n",
    "t_pred = t_model(X_tensor)\n",
    "t_acc = (torch.argmax(t_pred, 1) == y_tensor.flatten()).float().mean()\n",
    "print(f\"Accuracy of torch model is: {t_acc}\")\n",
    "\n",
    "k_pred = keras_model.predict(X)\n",
    "k_acc = (np.mean(np.argmax(k_pred, 1) == y.values.flatten()))\n",
    "print(f\"Accuracy of keras model is: {k_acc}\")\n",
    "\n",
    "keras_model.compile(loss=loss_fn)\n",
    "# Save Keras model\n",
    "keras_model.save(\"model.keras\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
